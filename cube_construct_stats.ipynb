{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 15 13:28:31 2018\n",
    "\n",
    "@author: rthomas\n",
    "\"\"\"\n",
    "#import calendar\n",
    "import datetime\n",
    "#from erddapy import ERDDAP\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set working directory for files to be saved\n",
    "working = os.path.normpath('C:/Users/rthomas/test_area/dashboard')\n",
    "\n",
    "# Choose from 'wave_spectral', 'wave_zero' or 'weather'\n",
    "data_types = ['wave_spectral', 'wave_zero', 'weather']\n",
    "\n",
    "source = 'url' # Populate with one of ['file','erddapy','url']\n",
    "\n",
    "for typed in data_types:\n",
    "    # Name files to save data\n",
    "    datafile = os.path.join(working,'%s/%s_data_raw.csv' % (typed, typed))\n",
    "    availfile = os.path.join(working,'%s/%s_data_availability.csv' % (typed, typed))\n",
    "    dailyfile = os.path.join(working,'%s/%s_daily_summary.csv' % (typed, typed))\n",
    "    \n",
    "    # Set global variables without 'buoy_id', 'latitude' and 'longitude'\n",
    "    now = datetime.date.today()\n",
    "    metadata = ['station_id',\n",
    "                'time']\n",
    "    print(typed)\n",
    "    # Set variables based on data type (typed)\n",
    "    if typed.lower() == 'wave_spectral':\n",
    "        dset_id = 'IWaveBNetwork_spectral'\n",
    "        syear = 2008    \n",
    "        master_params = ['PeakPeriod',\n",
    "                         'PeakDirection',\n",
    "                         'PeakSpread',\n",
    "                         'SignificantWaveHeight',\n",
    "                         'EnergyPeriod',\n",
    "                         'MeanWavePeriod_Tm01',\n",
    "                         'MeanWavePeriod_Tm02',\n",
    "                         'qcflag']\n",
    "        \n",
    "    elif typed.lower() == 'wave_zero':\n",
    "        dset_id = 'IWaveBNetwork_zerocrossing'\n",
    "        syear = 2008    \n",
    "        master_params = ['Hmax',\n",
    "                         'HmaxPeriod',\n",
    "                         'Havg',\n",
    "                         'Tavg',\n",
    "                         'qcflag']\n",
    "    \n",
    "    elif typed.lower() == 'weather':\n",
    "        dset_id = 'IWBNetwork'\n",
    "        syear = 2001\n",
    "        master_params = ['AtmosphericPressure',\n",
    "                         'WindDirection',\n",
    "                         'WindSpeed',\n",
    "                         'Gust',\n",
    "                         'WaveHeight',\n",
    "                         'WavePeriod',\n",
    "                         'MeanWaveDirection',\n",
    "                         'Hmax',\n",
    "                         'AirTemperature',\n",
    "                         'DewPoint',\n",
    "                         'SeaTemperature',\n",
    "                         'RelativeHumidity',\n",
    "                         'QC_Flag']\n",
    "    \n",
    "    # Get data from selected source\n",
    "    if source.lower() not in ['file','erddapy','url']:\n",
    "        print(\"Please check option has been entered correctly.\")\n",
    "    else:\n",
    "        if source.lower() == 'erddapy': # Use ERDDAP toolbox to call data from MI ERDDAP\n",
    "            e = ERDDAP(server='https://erddap.marine.ie/erddap',\n",
    "                       protocol='tabledap',)\n",
    "            e.response = 'csv'\n",
    "            e.dataset_id = dset_id\n",
    "            e.constraints = {\n",
    "                'time>=': '%s-01-01T00:00:00Z' % (syear),\n",
    "                'time<=': '%sT00:00:00Z' % (now.strftime('%Y-%m-%d')),\n",
    "            }\n",
    "            e.variables = metadata + master_params        \n",
    "            df = e.to_pandas()\n",
    "            \n",
    "            df.to_csv(datafile, sep=',') # Save data to file\n",
    "            \n",
    "        elif source.lower() == 'url': # Manually generated ERDDAP URL call\n",
    "            df = pd.DataFrame()\n",
    "            # Generate parameter component of URL\n",
    "            plist = ''\n",
    "            for item in metadata + master_params:\n",
    "                plist = plist+item+'%2C'\n",
    "            plist = plist[0:-3]    \n",
    "            # Iterate by year to reduce risk of time out\n",
    "            years = range(syear,now.year)\n",
    "            for year in years:    \n",
    "                url = \"https://erddap.marine.ie/erddap/tabledap/\"+dset_id+\".csv?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
    "                dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
    "                df = pd.concat([df,dfbyyear])\n",
    "                print(\"Downloaded %s\" % (year))\n",
    "            # Final call for data from start of this year upto and including yesterday\n",
    "            url = \"https://erddap.marine.ie/erddap/tabledap/\"+dset_id+\".csv?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now.strftime('%Y-%m-%d')+\"T00:00:00Z\"\n",
    "            dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
    "            df = pd.concat([df,dfbyyear])\n",
    "            print(\"Downloaded %s\" % (str(now.year)))\n",
    "            df.to_csv(datafile, sep=',') # Save data to file\n",
    "            print(\"Raw data downloaded and saved to csv.\")\n",
    "    \n",
    "        elif source.lower() == 'file': # Load from file if working offline and data has previously been downloaded from ERDDAP\n",
    "            df = pd.read_csv(datafile, index_col=0, parse_dates=True, infer_datetime_format=True)\n",
    "            \n",
    "        else:\n",
    "            print(\"Error in code logic. Please check.\")\n",
    "    \n",
    "    # Utilise quality control flags to clean data set\n",
    "    # Code to be written\n",
    "    \n",
    "    # Get data coverage by day, month, year, Day of Year and Date for each variable\n",
    "    # Add columns for date variables\n",
    "    #df['DayofYear'] = df.index.dayofyear\n",
    "    df['Date'] = df.index.date\n",
    "      \n",
    "    df_summ = df.groupby(['station_id','Date']).count().reset_index(level=['station_id','Date'])\n",
    "    \n",
    "    df_avail = pd.DataFrame()  \n",
    "    for stn in df_summ.station_id.unique().tolist():\n",
    "        df_stn = df_summ[df_summ['station_id']==stn]\n",
    "        if typed == 'weather' or stn == 'Westwave MK4':\n",
    "            res=24\n",
    "        else:\n",
    "            res=48\n",
    "        df_stn.loc[:,master_params] = df_stn.loc[:,master_params]/res*100\n",
    "        df_fulldates = pd.DataFrame(index = pd.date_range(df_stn.Date.min() - datetime.timedelta(days=df_stn.Date.min().day-1), df_stn.Date.max()))\n",
    "        df_fulldates['Date'] = df_fulldates.index.date\n",
    "        df_fulldates = df_fulldates.merge(df_stn, how='outer', left_on='Date', right_on='Date').fillna(0)\n",
    "        df_fulldates.station_id = stn\n",
    "        \n",
    "        df_avail = pd.concat([df_avail,df_fulldates])\n",
    "    \n",
    "    df_avail = df_avail.set_index(['station_id', 'Date'])\n",
    "    if typed != 'weather':\n",
    "        df_avail = df_avail.drop(['qcflag'], axis=1)\n",
    "    else:\n",
    "        df_avail = df_avail.drop(['QC_Flag'], axis=1)\n",
    "    df_avail.columns = pd.MultiIndex.from_product([df_avail.columns, ['avail']])\n",
    "\n",
    "       \n",
    "    # Save availability data to file\n",
    "    df_avail.to_csv(availfile, sep=',')\n",
    "    print(\"Data availability saved to file.\")\n",
    "\n",
    "    #%% Make daily summary statistics\n",
    "    # Split out parameter types for different summary statistics\n",
    "    \n",
    "    params = []\n",
    "    param_dir = []\n",
    "    for item in master_params:\n",
    "        if 'qc' not in item.lower():\n",
    "            if 'Dir' in item:\n",
    "                param_dir.append(item)\n",
    "            else:\n",
    "                params.append(item)\n",
    "    #%% Take a copy of the data\n",
    "    data = df\n",
    "            \n",
    "    # Get north and east components for directional measurements\n",
    "    param_comp = []\n",
    "    for dirtn in param_dir:\n",
    "        data['%s_n' % (dirtn)] = np.cos(data[dirtn]*np.pi/180)\n",
    "        param_comp.append('%s_n' % (dirtn))\n",
    "        data['%s_e' % (dirtn)] = np.sin(data[dirtn]*np.pi/180)\n",
    "        param_comp.append('%s_e' % (dirtn))\n",
    "        \n",
    "    # Resample for summary statistics for non-directional measurements\n",
    "    daily = data.groupby(['station_id','Date'])[params].agg(['min','max','mean','std'])\n",
    "    \n",
    "    if len(param_dir)!=0:\n",
    "        # Resample for mean and std for directional measurement components (north and east)\n",
    "        data2 = data.groupby(['station_id','Date'])[param_comp].agg(['mean','std'])\n",
    "           \n",
    "        # Recalculate direction mean and std from averaged components (north and east)\n",
    "        # Add directly into daily dataframe\n",
    "        for dirtn in param_dir:\n",
    "            daily[(dirtn, 'mean')] = (360 + np.arctan2(data2[('%s_e' % (dirtn), 'mean')], data2[('%s_n' % (dirtn), 'mean')]) * 180/np.pi) % 360\n",
    "            daily[(dirtn, 'std')] = (360 + np.arctan2(data2[('%s_e' % (dirtn), 'std')], data2[('%s_n' % (dirtn), 'std')]) * 180/np.pi) % 360\n",
    "            daily[(dirtn, 'max')] = np.nan\n",
    "            daily[(dirtn, 'min')] = np.nan\n",
    "   \n",
    "    # Sort daily dataframe\n",
    "    daily = daily[sorted(daily.columns.tolist())]\n",
    "    \n",
    "    # Save statistical data to file\n",
    "    daily.to_csv(dailyfile, sep=',')\n",
    "    print(\"Daily summary data saved to csv.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
