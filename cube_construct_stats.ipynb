{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required toolboxes and then select dataset of interest from the dropdown list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 15 13:28:31 2018\n",
    "\n",
    "@author: rthomas\n",
    "\"\"\"\n",
    "#import calendar\n",
    "import datetime\n",
    "#from erddapy import ERDDAP\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = widgets.Dropdown(\n",
    "    options=['wave_spectral', 'wave_zero', 'weather'],\n",
    "    description='Buoy data type:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the selected dataset from the Marine Institute ERDDAP instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'url' # Populate with one of ['erddapy','url']\n",
    "\n",
    "typed = dtype.value\n",
    "# Set global variables without 'buoy_id', 'latitude' and 'longitude'\n",
    "now = datetime.date.today()\n",
    "metadata = ['station_id',\n",
    "            'time']\n",
    "print(typed)\n",
    "# Set variables based on data type (typed)\n",
    "if typed.lower() == 'wave_spectral':\n",
    "    dset_id = 'IWaveBNetwork_spectral'\n",
    "    syear = 2008    \n",
    "    master_params = ['PeakPeriod',\n",
    "                     'PeakDirection',\n",
    "                     'PeakSpread',\n",
    "                     'SignificantWaveHeight',\n",
    "                     'EnergyPeriod',\n",
    "                     'MeanWavePeriod_Tm01',\n",
    "                     'MeanWavePeriod_Tm02',\n",
    "                     'qcflag']\n",
    "\n",
    "elif typed.lower() == 'wave_zero':\n",
    "    dset_id = 'IWaveBNetwork_zerocrossing'\n",
    "    syear = 2008    \n",
    "    master_params = ['Hmax',\n",
    "                     'HmaxPeriod',\n",
    "                     'Havg',\n",
    "                     'Tavg',\n",
    "                     'qcflag']\n",
    "\n",
    "elif typed.lower() == 'weather':\n",
    "    dset_id = 'IWBNetwork'\n",
    "    syear = 2001\n",
    "    master_params = ['AtmosphericPressure',\n",
    "                     'WindDirection',\n",
    "                     'WindSpeed',\n",
    "                     'Gust',\n",
    "                     'WaveHeight',\n",
    "                     'WavePeriod',\n",
    "                     'MeanWaveDirection',\n",
    "                     'Hmax',\n",
    "                     'AirTemperature',\n",
    "                     'DewPoint',\n",
    "                     'SeaTemperature',\n",
    "                     'RelativeHumidity',\n",
    "                     'QC_Flag']\n",
    "\n",
    "# Get data from selected source\n",
    "if source.lower() not in ['erddapy','url']:\n",
    "    print(\"Please check option has been entered correctly.\")\n",
    "else:\n",
    "    if source.lower() == 'erddapy': # Use ERDDAP toolbox to call data from MI ERDDAP\n",
    "        e = ERDDAP(server='https://erddap.marine.ie/erddap',\n",
    "                   protocol='tabledap',)\n",
    "        e.response = 'csv'\n",
    "        e.dataset_id = dset_id\n",
    "        e.constraints = {\n",
    "            'time>=': '%s-01-01T00:00:00Z' % (syear),\n",
    "            'time<=': '%sT00:00:00Z' % (now.strftime('%Y-%m-%d')),\n",
    "        }\n",
    "        e.variables = metadata + master_params        \n",
    "        df = e.to_pandas()\n",
    "\n",
    "    elif source.lower() == 'url': # Manually generated ERDDAP URL call\n",
    "        df = pd.DataFrame()\n",
    "        # Generate parameter component of URL\n",
    "        plist = ''\n",
    "        for item in metadata + master_params:\n",
    "            plist = plist+item+'%2C'\n",
    "        plist = plist[0:-3]    \n",
    "        # Iterate by year to reduce risk of time out\n",
    "        years = range(syear,now.year)\n",
    "        for year in years:    \n",
    "            url = \"https://erddap.marine.ie/erddap/tabledap/\"+dset_id+\".csv?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
    "            dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
    "            df = pd.concat([df,dfbyyear])\n",
    "            print(\"Downloaded %s\" % (year))\n",
    "        # Final call for data from start of this year upto and including yesterday\n",
    "        url = \"https://erddap.marine.ie/erddap/tabledap/\"+dset_id+\".csv?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now.strftime('%Y-%m-%d')+\"T00:00:00Z\"\n",
    "        dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
    "        df = pd.concat([df,dfbyyear])\n",
    "        print(\"Downloaded %s\" % (str(now.year)))\n",
    "\n",
    "    else:\n",
    "        print(\"Error in code logic. Please check.\")\n",
    "\n",
    "    data_full = df\n",
    "    print(\"Full resolution data downloaded. Available as 'data_full'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see a table of the full resolution data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate data availability as a percentage of expected data per day for each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilise quality control flags to clean data set\n",
    "# Code to be added...\n",
    "\n",
    "\n",
    "# Add columns for date variables\n",
    "\n",
    "df['Date'] = df.index.date\n",
    "df['Year'] = df.index.year\n",
    "\n",
    "df_summ = df.groupby(['station_id','Date','Year']).count().reset_index(level=['station_id','Date','Year'])\n",
    "\n",
    "df_avail = pd.DataFrame()  \n",
    "for stn in df_summ.station_id.unique().tolist():\n",
    "    df_stn = df_summ[df_summ['station_id']==stn]\n",
    "    if typed == 'weather' or stn == 'Westwave MK4':\n",
    "        res=24\n",
    "    else:\n",
    "        res=48\n",
    "    df_stn.loc[:,master_params] = df_stn.loc[:,master_params]/res*100\n",
    "    df_fulldates = pd.DataFrame(index = pd.date_range(df_stn.Date.min() - datetime.timedelta(days=df_stn.Date.min().day-1), \n",
    "                                                      df_stn.Date.max()))\n",
    "    df_fulldates['Date'] = df_fulldates.index.date\n",
    "    df_fulldates['Year'] = df_fulldates.index.year\n",
    "    df_fulldates = df_fulldates.merge(df_stn, how='outer', left_on='Date', right_on='Date').fillna(0)\n",
    "    df_fulldates.station_id = stn\n",
    "\n",
    "    df_avail = pd.concat([df_avail,df_fulldates])\n",
    "\n",
    "df_avail = df_avail.drop(['Year_y'], axis=1)\n",
    "df_avail.rename(columns={'Year_x': 'Year'}, inplace=True)\n",
    "df_avail = df_avail.set_index(['station_id', 'Date','Year'])\n",
    "if typed != 'weather':\n",
    "    df_avail = df_avail.drop(['qcflag'], axis=1)\n",
    "else:\n",
    "    df_avail = df_avail.drop(['QC_Flag'], axis=1)\n",
    "df_avail.columns = pd.MultiIndex.from_product([df_avail.columns, ['avail']])\n",
    "\n",
    "data_avail = df_avail\n",
    "print(\"Daily availability generated. Available as 'data_avail'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see a table of the full resolution data availability as a percentage of expected data per day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate daily summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out parameter types for different summary statistics\n",
    "\n",
    "params = []\n",
    "param_dir = []\n",
    "for item in master_params:\n",
    "    if 'qc' not in item.lower():\n",
    "        if 'Dir' in item:\n",
    "            param_dir.append(item)\n",
    "        else:\n",
    "            params.append(item)\n",
    "#%% Take a copy of the data\n",
    "data = df\n",
    "\n",
    "# Get north and east components for directional measurements\n",
    "param_comp = []\n",
    "for dirtn in param_dir:\n",
    "    data['%s_n' % (dirtn)] = np.cos(data[dirtn]*np.pi/180)\n",
    "    param_comp.append('%s_n' % (dirtn))\n",
    "    data['%s_e' % (dirtn)] = np.sin(data[dirtn]*np.pi/180)\n",
    "    param_comp.append('%s_e' % (dirtn))\n",
    "\n",
    "# Resample for summary statistics for non-directional measurements\n",
    "daily = data.groupby(['station_id','Date','Year'])[params].agg(['min','max','mean','std'])\n",
    "\n",
    "if len(param_dir)!=0:\n",
    "    # Resample for mean and std for directional measurement components (north and east)\n",
    "    data2 = data.groupby(['station_id','Date','Year'])[param_comp].agg(['mean','std'])\n",
    "\n",
    "    # Recalculate direction mean and std from averaged components (north and east)\n",
    "    # Add directly into daily dataframe\n",
    "    for dirtn in param_dir:\n",
    "        daily[(dirtn, 'mean')] = (360 + np.arctan2(data2[('%s_e' % (dirtn), 'mean')], data2[('%s_n' % (dirtn), 'mean')]) * 180/np.pi) % 360\n",
    "        daily[(dirtn, 'std')] = (360 + np.arctan2(data2[('%s_e' % (dirtn), 'std')], data2[('%s_n' % (dirtn), 'std')]) * 180/np.pi) % 360\n",
    "        daily[(dirtn, 'max')] = np.nan\n",
    "        daily[(dirtn, 'min')] = np.nan\n",
    "\n",
    "# Sort daily dataframe\n",
    "daily = daily[sorted(daily.columns.tolist())]\n",
    "data_daily = daily\n",
    "print(\"Daily statistics generated. Available as 'data_daily'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see a table of the daily summary statistics data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data with interactive widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(station, year, xaxis, yaxis, stat):\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    plotdata = data_daily.loc[station]\n",
    "    \n",
    "    if xaxis in ('PeakDirection'):\n",
    "        statx = 'mean'\n",
    "    else:\n",
    "        statx = stat\n",
    "    if yaxis in ('PeakDirection'):\n",
    "        staty = 'mean'\n",
    "    else:\n",
    "        staty = stat\n",
    "        \n",
    "    x = plotdata.loc[idx[:,year],idx[[xaxis],statx]].values\n",
    "    y = plotdata.loc[idx[:,year],idx[[yaxis],staty]].values\n",
    "\n",
    "    if xaxis in ('PeakDirection'):\n",
    "        ax = plt.subplot(111, projection='polar')\n",
    "        ax.set_theta_direction(-1)      # Set degrees to match compass rose\n",
    "        ax.set_theta_zero_location(\"N\") # Set zero to north on the plot\n",
    "        ax.set_rlabel_position(180)     # Set labels to area on plot with minimal data\n",
    "        ax = plt.scatter(x*np.pi/180, y)\n",
    "        plt.title(\"Location: %s Year: %s\" % (station,year))\n",
    "        plt.xlabel(\"%s (%s) [unit]\" % (yaxis, staty))\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        l = plt.plot(x, y,'o')\n",
    "        plt.setp(l, markersize=5)\n",
    "        plt.setp(l, markerfacecolor='C0')\n",
    "        plt.title(\"Location: %s Year: %s\" % (station,year))\n",
    "        plt.xlabel(\"%s (%s) [unit]\" % (xaxis, statx))\n",
    "        plt.ylabel(\"%s (%s) [unit]\" % (yaxis, staty))\n",
    "        plt.show()\n",
    "\n",
    "interact(plotting,\n",
    "    station = widgets.Dropdown(\n",
    "        options=data_daily.index.levels[0].tolist(),\n",
    "        description='Location:',\n",
    "        disabled=False),\n",
    "\n",
    "    year = widgets.IntSlider(\n",
    "        min = int(data_daily.index.levels[2].min()),\n",
    "        max = int(data_daily.index.levels[2].max()),\n",
    "        description = 'Year:'),\n",
    "\n",
    "    xaxis = widgets.RadioButtons(\n",
    "        options=data_daily.columns.levels[0].tolist(),\n",
    "        description='x-axis:',\n",
    "        disabled=False),\n",
    "\n",
    "    yaxis = widgets.RadioButtons(\n",
    "        options=data_daily.columns.levels[0].tolist(),\n",
    "        description='y-axis:',\n",
    "        disabled=False),\n",
    "\n",
    "    stat = widgets.RadioButtons(\n",
    "        options=data_daily.columns.levels[1].tolist(),\n",
    "        description='Statistic:',\n",
    "        disabled=False),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
