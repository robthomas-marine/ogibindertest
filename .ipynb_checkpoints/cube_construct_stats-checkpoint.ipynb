{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required toolboxes and create dropdown list for dataset selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 15 13:28:31 2018\n",
    "\n",
    "@author: rthomas\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dtype = widgets.Dropdown(\n",
    "    options=['wave_spectral', 'wave_zero', 'weather'],\n",
    "    disabled=False,\n",
    ")\n",
    "print(\"Select dataset to use:\")\n",
    "display(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to download the selected dataset from the Marine Institute ERDDAP instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typed = dtype.value\n",
    "print(typed)\n",
    "\n",
    "# Set ERDDAP server details\n",
    "s = 'https://erddap.marine.ie/erddap'\n",
    "p = 'tabledap'\n",
    "r = 'csv'\n",
    "\n",
    "# Set global variables for the parameters without 'buoy_id', 'latitude' and 'longitude' in the list\n",
    "now = datetime.date.today()\n",
    "now_string = now.strftime('%Y-%m-%d')\n",
    "\n",
    "metadata = ['station_id',\n",
    "            'time']\n",
    "\n",
    "# Set variables based on data type (typed)\n",
    "if typed.lower() == 'wave_spectral':\n",
    "    dataset_id = 'IWaveBNetwork_spectral'\n",
    "    syear = 2008    \n",
    "    master_params = ['PeakPeriod',\n",
    "                     'PeakDirection',\n",
    "                     'PeakSpread',\n",
    "                     'SignificantWaveHeight',\n",
    "                     'EnergyPeriod',\n",
    "                     'MeanWavePeriod_Tm01',\n",
    "                     'MeanWavePeriod_Tm02',\n",
    "                     'qcflag']\n",
    "\n",
    "elif typed.lower() == 'wave_zero':\n",
    "    dataset_id = 'IWaveBNetwork_zerocrossing'\n",
    "    syear = 2008    \n",
    "    master_params = ['Hmax',\n",
    "                     'HmaxPeriod',\n",
    "                     'Havg',\n",
    "                     'Tavg',\n",
    "                     'qcflag']\n",
    "\n",
    "elif typed.lower() == 'weather':\n",
    "    dataset_id = 'IWBNetwork'\n",
    "    syear = 2001\n",
    "    master_params = ['AtmosphericPressure',\n",
    "                     'WindDirection',\n",
    "                     'WindSpeed',\n",
    "                     'Gust',\n",
    "                     'WaveHeight',\n",
    "                     'WavePeriod',\n",
    "                     'MeanWaveDirection',\n",
    "                     'Hmax',\n",
    "                     'AirTemperature',\n",
    "                     'DewPoint',\n",
    "                     'SeaTemperature',\n",
    "                     'RelativeHumidity',\n",
    "                     'QC_Flag']\n",
    "\n",
    "# Generate parameter component of URL\n",
    "plist = ''\n",
    "for item in metadata + master_params:\n",
    "    plist = plist+item+'%2C'\n",
    "plist = plist[0:-3]\n",
    "\n",
    "# Create dataframe for population\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate by year to reduce risk of time out on large time-series\n",
    "years = range(syear,now.year)\n",
    "for year in years:    \n",
    "    url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
    "    dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
    "    df = pd.concat([df,dfbyyear])\n",
    "    print(\"Downloaded %s\" % (year))\n",
    "\n",
    "# Final call for data from start of current year upto midnight of the current day\n",
    "url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now_string+\"T00:00:00Z\"\n",
    "dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
    "df = pd.concat([df,dfbyyear])\n",
    "print(\"Downloaded %s\" % (str(now.year)))\n",
    "\n",
    "# Make a copy of the unaltered data download\n",
    "data_full = df.copy()\n",
    "print(\"Full resolution data downloaded. Available as 'data_full'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to see full resolution data dataframe structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate data availability as a percentage of expected data per day for each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilise quality control flags to clean data set\n",
    "# Code to be added...\n",
    "\n",
    "\n",
    "\n",
    "# Take a working copy of the downloaded data\n",
    "data = df.copy()\n",
    "\n",
    "# Add columns for date variable\n",
    "data['Date'] = data.index.date\n",
    "\n",
    "# Get a count of data points grouped by station and date\n",
    "data_summ = data.groupby(['station_id','Date']).count().reset_index(level=['station_id','Date'])\n",
    "\n",
    "# Create master availability dataframe to hold count converted to percentage of expected data points per day\n",
    "data_avail = pd.DataFrame()  \n",
    "\n",
    "# Loop through each station due to different data resolutions and calculate percentages\n",
    "for stn in data_summ.station_id.unique().tolist():\n",
    "    data_stn = data_summ[data_summ['station_id']==stn].copy()\n",
    "\n",
    "    # Set the expected number of data points per day for a buoy type or station\n",
    "    if typed == 'weather' or stn == 'Westwave MK4':\n",
    "        res=24\n",
    "    else:\n",
    "        res=48\n",
    "\n",
    "    # Convert counts to percentage\n",
    "    data_stn.loc[:,master_params] = data_stn.loc[:,master_params]/res*100\n",
    "    \n",
    "\n",
    "    # Expand date range to cover full months.\n",
    "    # Enables accurate calculation of monthly perentage return from the daily data when plotting\n",
    "    data_fulldates = pd.DataFrame(index = pd.date_range(data_stn.Date.min() - datetime.timedelta(days=data_stn.Date.min().day-1), \n",
    "                                                      data_stn.Date.max()))\n",
    "\n",
    "    # Add date factors to faciliate plotting\n",
    "    data_fulldates['Date'] = data_fulldates.index.date\n",
    "    data_fulldates['Year'] = data_fulldates.index.year\n",
    "    data_fulldates['Month'] = data_fulldates.index.month\n",
    "    data_fulldates['DOY'] = data_fulldates.index.dayofyear\n",
    "    \n",
    "    # Merge individual station dataframe into master availability dataframe and fill blanks dates with zero\n",
    "    data_fulldates = data_fulldates.merge(data_stn, how='outer', left_on='Date', right_on='Date').fillna(0)\n",
    "    # Set station\n",
    "    data_fulldates.loc[:,'station_id'] = stn\n",
    "    # Add data for the station to the master availability data frame\n",
    "    data_avail = pd.concat([data_avail,data_fulldates])\n",
    "\n",
    "# Set indices and tidy up dataframe\n",
    "data_avail = data_avail.set_index(['station_id', 'Date','Year','Month','DOY'])\n",
    "\n",
    "if typed != 'weather':\n",
    "    qc = 'qcflag'\n",
    "else:\n",
    "    qc = 'QC_Flag'\n",
    "\n",
    "data_avail = data_avail.drop([qc], axis=1)\n",
    "data_avail.columns = pd.MultiIndex.from_product([data_avail.columns, ['avail']])\n",
    "\n",
    "print(\"Daily availability generated. Available as 'data_avail'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to see data availability dataframe structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avail.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate daily summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out parameter types for different summary statistics\n",
    "\n",
    "params = []\n",
    "param_dir = []\n",
    "for item in master_params:\n",
    "    if 'qc' not in item.lower():\n",
    "        if 'Dir' in item:\n",
    "            param_dir.append(item)\n",
    "        else:\n",
    "            params.append(item)\n",
    "#%% Take a copy of the data\n",
    "data = df.copy()\n",
    "data['Date'] = data.index.date\n",
    "data['Year'] = data.index.year\n",
    "\n",
    "# Get north and east components for directional measurements\n",
    "param_comp = []\n",
    "for dirtn in param_dir:\n",
    "    data['%s_n' % (dirtn)] = np.cos(data[dirtn]*np.pi/180)\n",
    "    param_comp.append('%s_n' % (dirtn))\n",
    "    data['%s_e' % (dirtn)] = np.sin(data[dirtn]*np.pi/180)\n",
    "    param_comp.append('%s_e' % (dirtn))\n",
    "\n",
    "# Resample for summary statistics for non-directional measurements\n",
    "daily = data.groupby(['station_id','Date','Year'])[params].agg(['min','max','mean','std'])\n",
    "\n",
    "if len(param_dir)!=0:\n",
    "    # Resample for mean and std for directional measurement components (north and east)\n",
    "    data2 = data.groupby(['station_id','Date','Year'])[param_comp].agg(['mean','std'])\n",
    "\n",
    "    # Recalculate direction mean and std from averaged components (north and east)\n",
    "    # Add directly into daily dataframe\n",
    "    for dirtn in param_dir:\n",
    "        daily[(dirtn, 'mean')] = (360 + np.arctan2(data2[('%s_e' % (dirtn), 'mean')], data2[('%s_n' % (dirtn), 'mean')]) * 180/np.pi) % 360\n",
    "        daily[(dirtn, 'std')] = (360 + np.arctan2(data2[('%s_e' % (dirtn), 'std')], data2[('%s_n' % (dirtn), 'std')]) * 180/np.pi) % 360\n",
    "        daily[(dirtn, 'max')] = np.nan\n",
    "        daily[(dirtn, 'min')] = np.nan\n",
    "\n",
    "# Sort daily dataframe\n",
    "daily = daily[sorted(daily.columns.tolist())]\n",
    "data_daily = daily\n",
    "print(\"Daily statistics generated. Available as 'data_daily'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to see the daily summary statistics dataframe structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data with interactive widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plot_daily = data_daily.loc[data_daily.index.levels[0].tolist()[0]]\n",
    "\n",
    "def plotting(station, year, xaxis, yaxis, stat):\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    plot_daily = data_daily.loc[station]\n",
    "    \n",
    "    if xaxis in ('PeakDirection','WindDirection','MeanWaveDirection'):\n",
    "        statx = 'mean'\n",
    "    else:\n",
    "        statx = stat\n",
    "    if yaxis in ('PeakDirection','WindDirection','MeanWaveDirection'):\n",
    "        staty = 'mean'\n",
    "    else:\n",
    "        staty = stat\n",
    "        \n",
    "    x = plot_daily.loc[idx[:,year],idx[[xaxis],statx]].values\n",
    "    y = plot_daily.loc[idx[:,year],idx[[yaxis],staty]].values\n",
    "\n",
    "    if xaxis in ('PeakDirection','WindDirection','MeanWaveDirection'):\n",
    "        ax = plt.subplot(111, projection='polar')\n",
    "        ax.set_theta_direction(-1)      # Set degrees to match compass rose\n",
    "        ax.set_theta_zero_location(\"N\") # Set zero to north on the plot\n",
    "        ax.set_rlabel_position(180)     # Set labels to area on plot with minimal data\n",
    "        ax = plt.scatter(x*np.pi/180, y)\n",
    "        plt.title(\"Location: %s Year: %s\" % (station,year))\n",
    "        plt.xlabel(\"%s (%s) [unit]\" % (yaxis, staty))\n",
    "\n",
    "    else:\n",
    "        l = plt.plot(x, y,'o')\n",
    "        plt.setp(l, markersize=5)\n",
    "        plt.setp(l, markerfacecolor='C0')\n",
    "        plt.title(\"Location: %s Year: %s\" % (station,year))\n",
    "        plt.xlabel(\"%s (%s) [unit]\" % (xaxis, statx))\n",
    "        plt.ylabel(\"%s (%s) [unit]\" % (yaxis, staty))\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "interact(plotting,\n",
    "    station = widgets.Dropdown(\n",
    "        options=data_daily.index.levels[0].tolist(),\n",
    "        description='Location:',\n",
    "        disabled=False),\n",
    "\n",
    "    year = widgets.IntSlider(\n",
    "        min = int(plot_daily.index.levels[1].min()),\n",
    "        max = int(plot_daily.index.levels[1].max()),\n",
    "        description = 'Year:'),\n",
    "\n",
    "    xaxis = widgets.Dropdown(\n",
    "        options=data_daily.columns.levels[0].tolist(),\n",
    "        description='x-axis:',\n",
    "        disabled=False),\n",
    "\n",
    "    yaxis = widgets.Dropdown(\n",
    "        options=data_daily.columns.levels[0].tolist(),\n",
    "        description='y-axis:',\n",
    "        disabled=False),\n",
    "\n",
    "    stat = widgets.RadioButtons(\n",
    "        options=data_daily.columns.levels[1].tolist(),\n",
    "        description='Statistic:',\n",
    "        disabled=False),\n",
    "        )\n",
    "\n",
    "def avail_map(station1,parameter1,interval):\n",
    "    plot_avail = data_avail.loc[station1]\n",
    "    plot_avail.columns = plot_avail.columns.droplevel(level=1)\n",
    "    \n",
    "    if interval == 'Day':\n",
    "        plot_avail_set = plot_avail\n",
    "        ycol = 'DOY'\n",
    "        tag=False\n",
    "    elif interval == 'Month':\n",
    "        plot_avail_set = plot_avail.groupby(['Year','Month'])[data_avail.columns.levels[0].tolist()].agg(['mean'])\n",
    "        ycol='Month'\n",
    "        tag=True\n",
    "        plot_avail_set.columns = plot_avail_set.columns.droplevel(level=1)\n",
    "\n",
    "    plot_avail_set = plot_avail_set.reset_index()\n",
    "    pivot = plot_avail_set.pivot(index='Year', columns=ycol, values=parameter1)\n",
    "    ax = sns.heatmap(pivot,annot=tag)\n",
    "    plt.title(\"%s data availability (as percentage per %s): %s\" % (station1, interval, parameter1))\n",
    "    plt.show()\n",
    "    \n",
    "interact(avail_map,    \n",
    "    station1 = widgets.Dropdown(\n",
    "        options=data_avail.index.levels[0].tolist(),\n",
    "        description='Location:',\n",
    "        disabled=False),\n",
    "         \n",
    "    parameter1 = widgets.Dropdown(\n",
    "        options=data_avail.columns.levels[0].tolist(),\n",
    "        description='Parameter:',\n",
    "        disabled=False),\n",
    "    \n",
    "    interval = widgets.RadioButtons(\n",
    "        options=['Month','Day'],\n",
    "        description='Interval:',\n",
    "        disabled=False),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commands to save data as csv files. \n",
    "\n",
    "Will not work from MyBinder container.\n",
    "\n",
    "Input details of the working directory to save the csv files and uncomment the commands (remove the # from the start of each line) to make the cells run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working_directory = os.path.normpath('C:/Downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datafile = os.path.join(working,'%s_data_raw.csv' % (typed, typed))\n",
    "#availfile = os.path.join(working,'%s_data_availability.csv' % (typed, typed))\n",
    "#dailyfile = os.path.join(working,'%s_daily_summary.csv' % (typed, typed))\n",
    "\n",
    "#data_full.to_csv(datafile, sep=',')\n",
    "#data_avail.to_csv(availfile, sep=',')\n",
    "#data_daily.to_csv(dailyfile, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
